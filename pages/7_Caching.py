# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
import time
from transformers import pipeline

st.write("# Cache")
st.markdown("> `Caching` stores the results of slow function calls, so they only need to run once. This makes your app much faster and helps with persisting objects across reruns.")
st.markdown("`Caching`å°±æ˜¯èƒ½è®°ä½ä¹‹å‰çš„ä¸€äº›slow function callsï¼Œè®©æˆ‘ä»¬æ¯æ¬¡rerunçš„æ—¶å€™å‡å°‘è¿ç®—å’Œè°ƒç”¨ã€‚")
st.markdown("- `st.cache_data`æ˜¯ç¼“å­˜è¿”å›æ•°æ®çš„è®¡ç®—çš„æ¨èæ–¹æ³•ï¼šä»CSVåŠ è½½æ•°æ®å¸§ã€è½¬æ¢NumPyæ•°ç»„ã€æŸ¥è¯¢APIæˆ–ä»»ä½•å…¶ä»–è¿”å›å¯åºåˆ—åŒ–æ•°æ®å¯¹è±¡ï¼ˆstrã€intã€floatã€DataFrameã€arrayã€listç­‰ï¼‰çš„å‡½æ•°ã€‚")
st.markdown("- `st.cache_resource`æ˜¯ç¼“å­˜å…¨å±€èµ„æºï¼ˆå¦‚MLæ¨¡å‹æˆ–æ•°æ®åº“è¿æ¥ï¼‰çš„æ¨èæ–¹æ³•â€“å½“ä½ ä¸æƒ³å¤šæ¬¡åŠ è½½çš„ä¸å¯åºåˆ—åŒ–å¯¹è±¡æ—¶å¯ä»¥ä½¿ç”¨å®ƒï¼Œst.cache_resourceå¯ä»¥åœ¨åº”ç”¨çš„æ‰€æœ‰é‡æ–°è¿è¡Œå’Œä¼šè¯ä¹‹é—´å…±äº«è¿™äº›èµ„æºã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¯¹ç¼“å­˜è¿”å›å€¼çš„ä»»ä½•æ›´æ”¹éƒ½ä¼šç›´æ¥æ”¹å˜ç¼“å­˜ä¸­çš„å¯¹è±¡ã€‚")
st.write("å®åœ¨ä¸çŸ¥é“é€‰å•¥å°±æ— è„‘`st.cache_data`å°±å¥½")

st.write('---')

st.write("### Cache Data")
@st.cache_data  # ğŸ‘ˆ Add the caching decorator
def load_data(url):
    st.write(time.time())
    df = pd.read_csv(url)
    return df

df = load_data("https://github.com/plotly/datasets/raw/master/uber-rides-data1.csv")
st.dataframe(df)

@st.cache_data(ttl=3600)
def transform(df):
    df = df.filter(items=['one', 'three'])
    df = df.apply(np.sum, axis=0)
    return df


st.code("""
connection = database.connect()
@st.cache_data
def query():
    return pd.read_sql_query("SELECT * from table", connection)

Initialize connection.
conn = st.connection("snowflake")

# Load the table as a dataframe using the Snowpark Session.
@st.cache_data
def load_table():
    session = conn.session()
    return session.table("mytable").to_pandas()

df = load_table()

# Print results.
for row in df.itertuples():
    st.write(f"{row.NAME} has a :{row.PET}:")
            """)


st.button("Rerun")


st.write("### Cache Resources")
st.write("#### ML Model")
st.code("""
@st.cache_resource  # ğŸ‘ˆ Add the caching decorator
def load_model():
    return pipeline("sentiment-analysis")

model = load_model()

query = st.text_input("Your query", value="I love Streamlit! ğŸˆ")
if query:
    result = model(query)[0]  # ğŸ‘ˆ Classify the query text
    st.write(result)
""")

st.write("#### Database connections")
st.code("""
@st.cache_resource
def init_connection():
    host = "hh-pgsql-public.ebi.ac.uk"
    database = "pfmegrnargs"
    user = "reader"
    password = "NWDMCE5xdipIjRrp"
    return psycopg2.connect(host=host, database=database, user=user, password=password)

conn = init_connection()
            """)